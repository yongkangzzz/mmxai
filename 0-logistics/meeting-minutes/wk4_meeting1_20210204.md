# Date
04/02/2020

# Internal/Supervisor
supervisor

# Attendees
all group members, Dr. Pranava Madhyastha, Prof. Lucia Specia

# Agenda
1. General progress update (mmf, MMBT)
2. Technical progress
3. Q&A

# Details
## Group progress
Junqi J reported the group progress to the supervisors:

1. finished interim report one
2. set up mmf env on both local and google colab machines
3. trained an MMBT model for hateful meme challenge
4. downloaded pre-trained MMBT model for hateful meme challenge

## LIME
Junqi J and Yongkang Z reported the progress about the LIME package:

* showed an example of LIME applying to mmf MMBT model (only image input)
* major challenge was the computational time ~ 2hrs
* next step: apply LIME to also text input

### Suggestions from Dr. Pranava Madhyastha
1. texts in the image might occlude the results -> excluding the text from the image might improve the results
2. could try to implement an object detector to extract the minimum semantic unit to shorten the computational time

## SHARP
Zhi W presented the progress related to SHARP package:

* SHARP and LIME show similar interface
* trying to apply SHARP method to text input of mmf MMBT model

### Suggestions from Dr. Pranava Madhyastha
* very similar to the suggestions as for the LIME group (text exclusion and object detection)

### Q&A (Zhi W and Dr. Pranava Madhyastha)
Q: What interface this project should use?

A: Pytorch


Q: Is the sample size big enough? Do we need to consider the effects of sample size?

A: Assume sample size is enough for now

## TorchRay
Chenyu Z and Bojia M presented the progress related to TorchRay package:
1. trying to apply extremal perturbation method to the mmf MMBT model

### Q&A (Bojia M, Chenyu Z and Dr. Pranava Madhyastha)
Q: Difficulties in fusing both the text and the image input. Any suggestion?

A: Try looking into how MMBT fuse those two inputs

Q: Extremal perturbation uses masks which can only be applied to 2D image inputs. Any suggestion on how we could develop a new mask for text input?

A: Try start from a single word then expend the mask. Keep in mind the MMBT use BERT for text input pre-processing

# Group Q&A
## Q: Different multimodal models might takes different input types. Should our project just focus on the models in mmf or we are required to explain any general model?

A: It is possible to apply SHARP and LIME to general model as these methods are model-independent. TorchRay methods are model-dependent so it might be difficult to do so.
